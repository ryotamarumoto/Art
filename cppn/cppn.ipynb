{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc880971-eec5-41c1-9954-ad734132848e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCPPN\u001b[39;00m():\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, z_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, c_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8.0\u001b[39m, net_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ops'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Implementation of Compositional Pattern Producing Networks in Tensorflow\n",
    "\n",
    "https://en.wikipedia.org/wiki/Compositional_pattern-producing_network\n",
    "\n",
    "@hardmaru, 2016\n",
    "@w4nderlust, 2017\n",
    "\n",
    "'''\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from ops import *\n",
    "\n",
    "\n",
    "class CPPN():\n",
    "    def __init__(self, batch_size=1, z_dim=32, c_dim=1, scale=8.0, net_size=32, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        z_dim: how many dimensions of the latent space vector (R^z_dim)\n",
    "        c_dim: 1 for mono, 3 for rgb.  dimension for output space.  you can modify code to do HSV rather than RGB.\n",
    "        net_size: number of nodes for each fully connected layer of cppn\n",
    "        scale: the bigger, the more zoomed out the picture becomes\n",
    "\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.net_size = net_size\n",
    "        x_dim = 256\n",
    "        y_dim = 256\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.scale = scale\n",
    "        self.c_dim = c_dim\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        # tf Graph batch of image (batch_size, height, width, depth)\n",
    "        self.batch = tf.placeholder(tf.float32, [batch_size, x_dim, y_dim, c_dim])\n",
    "\n",
    "        n_points = x_dim * y_dim\n",
    "        self.n_points = n_points\n",
    "\n",
    "        self.x_vec, self.y_vec, self.r_vec = self._coordinates(x_dim, y_dim, scale)\n",
    "\n",
    "        # latent vector\n",
    "        self.z = tf.placeholder(tf.float32, [self.batch_size, self.z_dim])\n",
    "        # inputs to cppn, like coordinates and radius from centre\n",
    "        self.x = tf.placeholder(tf.float32, [self.batch_size, None, 1])\n",
    "        self.y = tf.placeholder(tf.float32, [self.batch_size, None, 1])\n",
    "        self.r = tf.placeholder(tf.float32, [self.batch_size, None, 1])\n",
    "\n",
    "        # builds the generator network\n",
    "        self.G = self.generator(x_dim=self.x_dim, y_dim=self.y_dim)\n",
    "\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        # Initializing the tensor flow variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        # Launch the session\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def reinit(self):\n",
    "        init = tf.variables_initializer(tf.trainable_variables())\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def _coordinates(self, x_dim=32, y_dim=32, scale=1.0):\n",
    "        '''\n",
    "        calculates and returns a vector of x and y coordintes, and corresponding radius from the centre of image.\n",
    "        '''\n",
    "        n_points = x_dim * y_dim\n",
    "        # creates x and y ranges of x/y_dim numbers from -scale to +scale\n",
    "        x_range = scale * ((np.arange(x_dim) - (x_dim - 1) / 2.0) / (x_dim - 1) * 2)\n",
    "        y_range = scale * ((np.arange(y_dim) - (y_dim - 1) / 2.0) / (y_dim - 1) * 2)\n",
    "        # create all r distances from center for any combination of coordinates on x and y\n",
    "        x_mat = np.matmul(np.ones((y_dim, 1)), x_range.reshape((1, x_dim)))\n",
    "        y_mat = np.matmul(y_range.reshape((y_dim, 1)), np.ones((1, x_dim)))\n",
    "        r_mat = np.sqrt(x_mat * x_mat + y_mat * y_mat)\n",
    "        # transform the x x y matrices tiling as many of them as the batch size\n",
    "        # and reshaping to obtain a Ã¨batch_size, x*y, 1+ tensor\n",
    "        x_mat = np.tile(x_mat.flatten(), self.batch_size).reshape(self.batch_size, n_points, 1)\n",
    "        y_mat = np.tile(y_mat.flatten(), self.batch_size).reshape(self.batch_size, n_points, 1)\n",
    "        r_mat = np.tile(r_mat.flatten(), self.batch_size).reshape(self.batch_size, n_points, 1)\n",
    "        return x_mat, y_mat, r_mat\n",
    "\n",
    "    def generator(self, x_dim, y_dim, reuse=False):\n",
    "        if reuse:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "        net_size = self.net_size\n",
    "        n_points = x_dim * y_dim\n",
    "\n",
    "        # note that latent vector z is scaled to self.scale factor.\n",
    "        z_scaled = tf.reshape(self.z, [self.batch_size, 1, self.z_dim]) * \\\n",
    "                   tf.ones([n_points, 1], dtype=tf.float32) * self.scale\n",
    "        z_unroll = tf.reshape(z_scaled, [self.batch_size * n_points, self.z_dim])\n",
    "        x_unroll = tf.reshape(self.x, [self.batch_size * n_points, 1])\n",
    "        y_unroll = tf.reshape(self.y, [self.batch_size * n_points, 1])\n",
    "        r_unroll = tf.reshape(self.r, [self.batch_size * n_points, 1])\n",
    "\n",
    "        U = fully_connected(z_unroll, net_size, 'g_0_z') + \\\n",
    "            fully_connected(x_unroll, net_size, 'g_0_x', with_bias=False) + \\\n",
    "            fully_connected(y_unroll, net_size, 'g_0_y', with_bias=False) + \\\n",
    "            fully_connected(r_unroll, net_size, 'g_0_r', with_bias=False)\n",
    "\n",
    "        '''\n",
    "        Below are a bunch of examples of different CPPN configurations.\n",
    "        Feel free to comment out and experiment!\n",
    "        '''\n",
    "\n",
    "        ###\n",
    "        ### Example: 3 layers of tanh() layers, with net_size = 32 activations/layer\n",
    "        ###\n",
    "        # '''\n",
    "        H = tf.nn.tanh(U)\n",
    "        for i in range(3):\n",
    "            H = tf.nn.tanh(fully_connected(H, net_size, 'g_tanh_' + str(i)))\n",
    "        output = tf.sigmoid(fully_connected(H, self.c_dim, 'g_final'))\n",
    "        # '''\n",
    "\n",
    "        ###\n",
    "        ### Similar to example above, but instead the output is\n",
    "        ### a weird function rather than just the sigmoid\n",
    "        '''\n",
    "        H = tf.nn.tanh(U)\n",
    "        for i in range(3):\n",
    "          H = tf.nn.tanh(fully_connected(H, net_size, 'g_tanh_'+str(i)))\n",
    "        output = tf.sqrt(1.0-tf.abs(tf.tanh(fully_connected(H, self.c_dim, 'g_final'))))\n",
    "        '''\n",
    "\n",
    "        ###\n",
    "        ### Example: mixing softplus and tanh layers, with net_size = 32 activations/layer\n",
    "        ###\n",
    "        '''\n",
    "        H = tf.nn.tanh(U)\n",
    "        H = tf.nn.softplus(fully_connected(H, net_size, 'g_softplus_1'))\n",
    "        H = tf.nn.tanh(fully_connected(H, net_size, 'g_tanh_2'))\n",
    "        H = tf.nn.softplus(fully_connected(H, net_size, 'g_softplus_2'))\n",
    "        H = tf.nn.tanh(fully_connected(H, net_size, 'g_tanh_2'))\n",
    "        H = tf.nn.softplus(fully_connected(H, net_size, 'g_softplus_2'))\n",
    "        output = tf.sigmoid(fully_connected(H, self.c_dim, 'g_final'))\n",
    "        '''\n",
    "\n",
    "        ###\n",
    "        ### Example: mixing sinusoids, tanh and multiple softplus layers\n",
    "        ###\n",
    "        '''\n",
    "        H = tf.nn.tanh(U)\n",
    "        H = tf.nn.softplus(fully_connected(H, net_size, 'g_softplus_1'))\n",
    "        H = tf.nn.tanh(fully_connected(H, net_size, 'g_tanh_2'))\n",
    "        H = tf.nn.softplus(fully_connected(H, net_size, 'g_softplus_2'))\n",
    "        output = 0.5 * tf.sin(fully_connected(H, self.c_dim, 'g_final')) + 0.5\n",
    "        '''\n",
    "\n",
    "        ###\n",
    "        ### Example: residual network of 4 tanh() layers\n",
    "        ###\n",
    "        '''\n",
    "        H = tf.nn.tanh(U)\n",
    "        for i in range(3):\n",
    "          H = H+tf.nn.tanh(fully_connected(H, net_size, g_tanh_'+str(i)))\n",
    "        output = tf.sigmoid(fully_connected(H, self.c_dim, 'g_final'))\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        The final hidden later is pass through a fully connected sigmoid later, so outputs -> (0, 1)\n",
    "        Also, the output has a dimension of c_dim, so can be monotone or RGB\n",
    "        '''\n",
    "        result = tf.reshape(output, [self.batch_size, y_dim, x_dim, self.c_dim])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def generate(self, z=None, x_dim=26, y_dim=26, scale=8.0, **kwargs):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        If z is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z is drawn from prior in latent\n",
    "        space.\n",
    "        \"\"\"\n",
    "        if z is None:\n",
    "            z = np.random.uniform(-1.0, 1.0, size=(self.batch_size, self.z_dim)).astype(np.float32)\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "\n",
    "        G = self.generator(x_dim=x_dim, y_dim=y_dim, reuse=True)\n",
    "        x_vec, y_vec, r_vec = self._coordinates(x_dim, y_dim, scale=scale)\n",
    "        image = self.sess.run(G, feed_dict={self.z: z, self.x: x_vec, self.y: y_vec, self.r: r_vec})\n",
    "        return image\n",
    "\n",
    "    def close(self):\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e211d-4ac9-4682-a112-a2c877c84b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
